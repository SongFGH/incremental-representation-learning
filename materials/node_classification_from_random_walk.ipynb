{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from gensim.models.word2vec import PathLineSentences, LineSentence, Word2Vec\n",
    "from pathlib import Path\n",
    "from sklearn import model_selection, linear_model, preprocessing, svm\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "from sklearn.pipeline import make_pipeline\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Load random walks from output files**\n",
    "\n",
    "The word2vec model requires sentences of strings, so we convert node number to a string."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "rw_location = Path(\"./karate/path\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_walks_int = np.concatenate([\n",
    "    np.loadtxt(f.open(), delimiter='\\t', dtype=int)\n",
    "    for f in rw_location.glob(\"part-*\")\n",
    "])\n",
    "random_walks_str = [list(map(str, v)) for v in random_walks_int]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train word2vec embeddings using gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Word2Vec(random_walks_str, sg=1, size=20, window=5, min_count=0, \n",
    "                 workers=4, seed=1321, iter=10, compute_loss=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6837.341796875"
      ]
     },
     "execution_count": 238,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.get_latest_training_loss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.wv.save_word2vec_format(\"embeddings.out\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extract embeddings as matrix of size `n_nodes` × `d`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [],
   "source": [
    "V_w2v = model.wv.syn0\n",
    "n_nodes, d_emb = V_w2v.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Node labels:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [],
   "source": [
    "node_labels = np.zeros(n_nodes)\n",
    "node_labels[:10] = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Classification using single train/test split**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train acc: 0.95\n",
      "Test acc: 0.714285714286\n",
      "Train f1: 0.95\n",
      "Test f1: 0.714285714286\n"
     ]
    }
   ],
   "source": [
    "# Split using sklearn ShuffleSplit\n",
    "ss = model_selection.ShuffleSplit(n_splits=1,\n",
    "                                  train_size=0.6,\n",
    "                                  test_size=0.4)\n",
    "train_index, test_index = next(ss.split(V_w2v))\n",
    "\n",
    "train_data = V_w2v[train_index]\n",
    "test_data = V_w2v[test_index]\n",
    "train_labels = node_labels[train_index]\n",
    "test_labels  = node_labels[test_index]\n",
    "\n",
    "# Classifier choice\n",
    "#classifier = linear_model.LogisticRegression(C=10)\n",
    "classifier = svm.SVC(C=1)\n",
    "\n",
    "clf = make_pipeline(preprocessing.StandardScaler(), classifier)\n",
    "clf.fit(train_data, train_labels)\n",
    "\n",
    "train_pred = clf.predict(train_data)\n",
    "test_pred = clf.predict(test_data)\n",
    "\n",
    "print(\"Train acc:\", clf.score(train_data, train_labels))\n",
    "print(\"Test acc:\", clf.score(test_data, test_labels))\n",
    "print(\"Train f1:\", f1_score(train_labels, train_pred, average='micro'))\n",
    "print(\"Test f1:\", f1_score(test_labels, test_pred, average='micro'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**K-fold cross validation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train acc=0.880000,  Test acc=0.444444,  Train f1=0.880000,  Test f1=0.444444\n",
      "Train acc=0.960000,  Test acc=0.777778,  Train f1=0.960000,  Test f1=0.777778\n",
      "Train acc=0.961538,  Test acc=0.750000,  Train f1=0.961538,  Test f1=0.750000\n",
      "Train acc=0.923077,  Test acc=0.875000,  Train f1=0.923077,  Test f1=0.875000\n",
      "Average scores:\n",
      "Avg test acc=0.711806 [±0.161187],  Avg test f1=0.711806 [±0.161187]\n"
     ]
    }
   ],
   "source": [
    "kf = model_selection.KFold(n_splits=4, shuffle=True)\n",
    "\n",
    "acc_test_scores = []\n",
    "f1_test_scores = []\n",
    "for train_index, test_index in kf.split(V_w2v):\n",
    "    train_data = V_w2v[train_index]\n",
    "    test_data = V_w2v[test_index]\n",
    "    train_labels = node_labels[train_index]\n",
    "    test_labels  = node_labels[test_index]\n",
    "    \n",
    "    # Classifier choice\n",
    "    #classifier = linear_model.LogisticRegression(C=10)\n",
    "    classifier = svm.SVC(C=1)\n",
    "\n",
    "    clf = make_pipeline(preprocessing.StandardScaler(), classifier)\n",
    "    clf.fit(train_data, train_labels)\n",
    "\n",
    "    train_pred = clf.predict(train_data)\n",
    "    test_pred = clf.predict(test_data)\n",
    "\n",
    "    acc_train = clf.score(train_data, train_labels)\n",
    "    acc_test = clf.score(test_data, test_labels)\n",
    "    f1_train = f1_score(train_labels, train_pred, average='micro')\n",
    "    f1_test = f1_score(test_labels, test_pred, average='micro')\n",
    "    \n",
    "    acc_test_scores.append(acc_test)\n",
    "    f1_test_scores.append(f1_test)\n",
    "    \n",
    "    print(\"Train acc={:4f},  Test acc={:4f},  Train f1={:4f},  Test f1={:4f}\".format(\n",
    "        acc_train, acc_test, f1_train, f1_test\n",
    "    ))\n",
    "    \n",
    "print(\"Average scores:\")\n",
    "print(\"Avg test acc={:4f} [±{:2f}],  Avg test f1={:4f} [±{:2f}]\".format(\n",
    "    np.mean(acc_test_scores), np.std(acc_test_scores), \n",
    "    np.mean(f1_test_scores), np.std(f1_test_scores)\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:luigi]",
   "language": "python",
   "name": "conda-env-luigi-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
