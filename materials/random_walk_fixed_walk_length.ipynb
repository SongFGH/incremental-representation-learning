{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from gensim.models.word2vec import PathLineSentences, LineSentence, Word2Vec\n",
    "from pathlib import Path\n",
    "import networkx as nx\n",
    "from sklearn import model_selection, linear_model, preprocessing, svm\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "from sklearn.pipeline import make_pipeline\n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Load random walks from output files**\n",
    "\n",
    "The word2vec model requires sentences of strings, so we convert node number to a string."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G = nx.read_edgelist(\"/Users/Ganymedian/Desktop/dynamic-rw/datasets/karate.txt\", nodetype=int)\n",
    "A = nx.adjacency_matrix(G,nodelist=sorted(G.nodes())).toarray()\n",
    "d_w = A.sum(axis=1)\n",
    "M_theory = A.T / d_w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_walks(m, v, wl, nw):\n",
    "    fname = \"ar-\" + m + \"-wl\" + str(wl) + \"-nw\" + str(nw) + \"-\" + v\n",
    "    rws = np.concatenate([\n",
    "        np.loadtxt(f.open(), delimiter='\\t', dtype=int)\n",
    "        for f in rw_location.glob(fname + \"-*.txt\")\n",
    "        if f.stat().st_size > 0\n",
    "    ])\n",
    "    ars = np.vsplit(rws, 5)\n",
    "    return ars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "methods = [\"m1\", \"m2\", \"m3\", \"m4\"]\n",
    "nmethods = len(methods)\n",
    "num_runs = 5\n",
    "wl = 3\n",
    "nw = 100\n",
    "rw_location = Path(\"/Users/Ganymedian/Desktop/dynamic-rw/output/karate-test\")\n",
    "formats=['.-', '^-', '*-','x-']\n",
    "n_nodes = G.number_of_nodes()\n",
    "vertices = np.arange(1,n_nodes+1)\n",
    "print(vertices)\n",
    "\n",
    "for mm in range(nmethods):\n",
    "    print(methods[mm])\n",
    "    all_errors = []\n",
    "    for vv in vertices:\n",
    "        v = \"v\"+str(vv)\n",
    "        runs = read_walks(methods[mm], v, wl, nw)\n",
    "        errors = []\n",
    "        for rr in range(num_runs):\n",
    "            M_empirical = np.zeros((n_nodes, n_nodes))\n",
    "            for walk in runs[rr]:\n",
    "                for kk in range(wl - 1):\n",
    "                    M_empirical[walk[kk] - 1, walk[kk + 1] - 1] += 1\n",
    "\n",
    "            n_samples = M_empirical.sum()\n",
    "            M_empirical = M_empirical.T / np.maximum(M_empirical.sum(axis=1), 1)\n",
    "\n",
    "            errors.append(np.abs(M_theory - M_empirical).mean())\n",
    "\n",
    "        all_errors.append(errors)\n",
    "\n",
    "    means = np.mean(all_errors,axis=1)\n",
    "    stdv = np.std(all_errors, axis=1)\n",
    "    plt.errorbar(vertices, means, yerr=stdv, fmt=formats[mm], label=methods[mm], ms=10)\n",
    "    plt.xticks(vertices, rotation=-90)\n",
    "    plt.legend()\n",
    "\n",
    "fig_size = plt.rcParams[\"figure.figsize\"]\n",
    "fig_size[0] = 6\n",
    "fig_size[1] = 4\n",
    "plt.rcParams[\"figure.figsize\"] = fig_size\n",
    "plt.xlabel(\"Vertex ID\")\n",
    "plt.ylabel(\"Error\")\n",
    "plt.show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
